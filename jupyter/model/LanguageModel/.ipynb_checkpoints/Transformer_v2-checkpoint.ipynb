{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "317b40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/hoyoung/Desktop/pycharm_work/korean_grammar_corrector/bin')\n",
    "sys.path.append('/Users/hoyoung/Desktop/pycharm_work/korean_grammar_corrector/utils')\n",
    "\n",
    "import tensorflow_preprocess as tp\n",
    "from model.transformer_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe03da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../data/train/corpus_repair_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0939844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 24\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    # 레이블의 크기 : (batch_size, MAX_LENGTH - 1)\n",
    "    y_true = tf.reshape(y_true, shape = (-1, MAX_LENGTH-1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51052d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 15:37:04.217776: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "src = df['src'].apply(lambda x: tp.full_stop_filter(x))\n",
    "tgt = df['tgt'].apply(lambda x: tp.full_stop_filter(x))\n",
    "\n",
    "inputs, outputs, tokenizer = tp.tokenize_and_filter(src, tgt, max_length=24)\n",
    "dataset = tp.create_train_dataset(inputs, outputs, batch_size=64, buffer_size=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bf9e21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "d_model = 256\n",
    "num_layers = 5\n",
    "num_heads = 8\n",
    "dff = 512\n",
    "dropout = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size = tokenizer.vocab_size+2,\n",
    "    num_layers = num_layers,\n",
    "    dff = dff,\n",
    "    d_model = d_model,\n",
    "    num_heads = num_heads,\n",
    "    dropout = dropout,\n",
    "    name=\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfc6ac4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " encoder (Functional)           (None, None, 256)    4749824     ['inputs[0][0]',                 \n",
      "                                                                  'enc_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
      "                                e)                                                                \n",
      "                                                                                                  \n",
      " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, None, 256)    6068224     ['dec_inputs[0][0]',             \n",
      "                                                                  'encoder[0][0]',                \n",
      "                                                                  'look_ahead_mask[0][0]',        \n",
      "                                                                  'dec_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, None, 8259)   2122563     ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,940,611\n",
      "Trainable params: 12,940,611\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9391f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(128)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e79c650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"../../../checkpoint/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 모델의 가중치를 저장하는 콜백 만들기\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3c5b8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "157/157 [==============================] - ETA: 0s - loss: 4.0939 - accuracy: 0.0684\n",
      "Epoch 1: saving model to ../../../checkpoint/cp.ckpt\n",
      "157/157 [==============================] - 147s 936ms/step - loss: 4.0939 - accuracy: 0.0684\n",
      "Epoch 2/3\n",
      "157/157 [==============================] - ETA: 0s - loss: 3.6223 - accuracy: 0.1031\n",
      "Epoch 2: saving model to ../../../checkpoint/cp.ckpt\n",
      "157/157 [==============================] - 160s 1s/step - loss: 3.6223 - accuracy: 0.1031\n",
      "Epoch 3/3\n",
      "157/157 [==============================] - ETA: 0s - loss: 3.4050 - accuracy: 0.1177\n",
      "Epoch 3: saving model to ../../../checkpoint/cp.ckpt\n",
      "157/157 [==============================] - 151s 959ms/step - loss: 3.4050 - accuracy: 0.1177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9e55d9c040>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 3\n",
    "model.fit(dataset, epochs=epochs, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "511321fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp.ckpt.data-00000-of-00001', 'checkpoint', 'cp.ckpt.index']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4a6e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = transformer(\n",
    "    vocab_size = tokenizer.vocab_size+2,\n",
    "    num_layers = num_layers,\n",
    "    dff = dff,\n",
    "    d_model = d_model,\n",
    "    num_heads = num_heads,\n",
    "    dropout = dropout,\n",
    "    name=\"transformer_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d23bea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9e16b38070>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8f09f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ko_grammer_checker] *",
   "language": "python",
   "name": "conda-env-ko_grammer_checker-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
