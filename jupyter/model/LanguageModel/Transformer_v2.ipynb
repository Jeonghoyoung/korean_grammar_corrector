{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "399b47ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/hoyoung/Desktop/pycharm_work/korean_grammar_corrector/bin')\n",
    "sys.path.append('/Users/hoyoung/Desktop/pycharm_work/korean_grammar_corrector/utils')\n",
    "\n",
    "import tensorflow_preprocess as tp\n",
    "from model.transformer_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d95806ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../data/train/corpus_repair_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "164bc6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 24\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def call(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    # 레이블의 크기 : (batch_size, MAX_LENGTH - 1)\n",
    "    y_true = tf.reshape(y_true, shape = (-1, MAX_LENGTH-1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b1b64f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 09:47:04.077780: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "src = df['src'].apply(lambda x: tp.full_stop_filter(x))\n",
    "tgt = df['tgt'].apply(lambda x: tp.full_stop_filter(x))\n",
    "\n",
    "inputs, outputs, tokenizer = tp.tokenize_and_filter(src, tgt, max_length=24)\n",
    "dataset = tp.create_train_dataset(inputs, outputs, batch_size=64, buffer_size=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68cef09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "d_model = 256\n",
    "num_layers = 5\n",
    "num_heads = 8\n",
    "dff = 512\n",
    "dropout = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size = tokenizer.vocab_size+2,\n",
    "    num_layers = num_layers,\n",
    "    dff = dff,\n",
    "    d_model = d_model,\n",
    "    num_heads = num_heads,\n",
    "    dropout = dropout,\n",
    "    name=\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41d07ec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " encoder (Functional)           (None, None, 256)    4749824     ['inputs[0][0]',                 \n",
      "                                                                  'enc_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
      "                                e)                                                                \n",
      "                                                                                                  \n",
      " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, None, 256)    6068224     ['dec_inputs[0][0]',             \n",
      "                                                                  'encoder[0][0]',                \n",
      "                                                                  'look_ahead_mask[0][0]',        \n",
      "                                                                  'dec_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, None, 8259)   2122563     ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,940,611\n",
      "Trainable params: 12,940,611\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9201f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(128)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d7ae4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"../../../checkpoint/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 모델의 가중치를 저장하는 콜백 만들기\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff5db35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "157/157 [==============================] - ETA: 0s - loss: 4.0939 - accuracy: 0.0684\n",
      "Epoch 1: saving model to ../../../checkpoint/cp.ckpt\n",
      "157/157 [==============================] - 147s 936ms/step - loss: 4.0939 - accuracy: 0.0684\n",
      "Epoch 2/3\n",
      "157/157 [==============================] - ETA: 0s - loss: 3.6223 - accuracy: 0.1031\n",
      "Epoch 2: saving model to ../../../checkpoint/cp.ckpt\n",
      "157/157 [==============================] - 160s 1s/step - loss: 3.6223 - accuracy: 0.1031\n",
      "Epoch 3/3\n",
      "157/157 [==============================] - ETA: 0s - loss: 3.4050 - accuracy: 0.1177\n",
      "Epoch 3: saving model to ../../../checkpoint/cp.ckpt\n",
      "157/157 [==============================] - 151s 959ms/step - loss: 3.4050 - accuracy: 0.1177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9e55d9c040>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 3\n",
    "model.fit(dataset, epochs=epochs, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33b4b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../../my_checkpoint/transformer_model_1.3M_30epochs_weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a306dbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoint',\n",
       " 'transformer_model_1.3M_30epochs_weights.data-00000-of-00001',\n",
       " 'transformer_model_1.3M_30epochs_weights.index']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.dirname(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae10b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 128\n",
    "num_layers = 4\n",
    "num_heads = 4\n",
    "dff = 256\n",
    "dropout = 0.1\n",
    "vocab_size = 8224\n",
    "\n",
    "model2 = transformer(\n",
    "    vocab_size = vocab_size,\n",
    "    num_layers = num_layers,\n",
    "    dff = dff,\n",
    "    d_model = d_model,\n",
    "    num_heads = num_heads,\n",
    "    dropout = dropout,\n",
    "    name=\"transformer2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c397e142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9e10450490>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_weights(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c569b255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " encoder (Functional)           (None, None, 128)    1582592     ['inputs[0][0]',                 \n",
      "                                                                  'enc_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
      "                                e)                                                                \n",
      "                                                                                                  \n",
      " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, None, 128)    1847808     ['dec_inputs[0][0]',             \n",
      "                                                                  'encoder[0][0]',                \n",
      "                                                                  'look_ahead_mask[0][0]',        \n",
      "                                                                  'dec_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, None, 8224)   1060896     ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,491,296\n",
      "Trainable params: 4,491,296\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f914a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, MAX_LENGTH, model=model2):\n",
    "    # 입력 문장에 대한 전처리\n",
    "    sentence = tp.full_stop_filter(sentence)\n",
    "\n",
    "    # 입력 문장에 시작 토큰과 종료 토큰을 추가\n",
    "    sentence = tf.expand_dims(\n",
    "      [tokenizer.vocab_size] + tokenizer.encode(sentence) + [vocab_size+1], axis=0)\n",
    "\n",
    "    output = tf.expand_dims([vocab_size], 0)\n",
    "\n",
    "    # 디코더의 예측 시작\n",
    "    for i in range(MAX_LENGTH):\n",
    "        predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "        # 현재 시점의 예측 단어를 받아온다.\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "        if tf.equal(predicted_id, [vocab_size+1][0]):\n",
    "            break\n",
    "\n",
    "        # 현재 시점의 예측 단어를 output(출력)에 연결한다.\n",
    "        # output은 for문의 다음 루프에서 디코더의 입력이 된다.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    # 단어 예측이 모두 끝났다면 output을 리턴.\n",
    "    return tf.squeeze(output, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "def predict(sentence):\n",
    "    prediction = evaluate(sentence, 24)\n",
    "\n",
    "    # prediction == 디코더가 리턴한 챗봇의 대답에 해당하는 정수 시퀀스\n",
    "    # tokenizer.decode()를 통해 정수 시퀀스를 문자열로 디코딩.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd2e168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"이유른 신차의 경우 야 기퍼센트에서 시자캐요.\"\n",
    "t = tp.full_stop_filter(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59013ef3",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"embedding_16\" (type Embedding).\n\nindices[0,0] = 8257 is not in [0, 8224) [Op:ResourceGather]\n\nCall arguments received by layer \"embedding_16\" (type Embedding):\n  • inputs=tf.Tensor(shape=(1, 15), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(sentence, MAX_LENGTH, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 디코더의 예측 시작\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(MAX_LENGTH):\n\u001b[0;32m---> 13\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# 현재 시점의 예측 단어를 받아온다.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m predictions[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:, :]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ko_grammer_checker/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ko_grammer_checker/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7163\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7164\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"embedding_16\" (type Embedding).\n\nindices[0,0] = 8257 is not in [0, 8224) [Op:ResourceGather]\n\nCall arguments received by layer \"embedding_16\" (type Embedding):\n  • inputs=tf.Tensor(shape=(1, 15), dtype=float32)"
     ]
    }
   ],
   "source": [
    "evaluate(test, 24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4063f86e",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"embedding_16\" (type Embedding).\n\nindices[0,0] = 8257 is not in [0, 8224) [Op:ResourceGather]\n\nCall arguments received by layer \"embedding_16\" (type Embedding):\n  • inputs=tf.Tensor(shape=(1, 15), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(sentence):\n\u001b[0;32m---> 33\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# prediction == 디코더가 리턴한 챗봇의 대답에 해당하는 정수 시퀀스\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# tokenizer.decode()를 통해 정수 시퀀스를 문자열로 디코딩.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     predicted_sentence \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[1;32m     38\u001b[0m       [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m prediction \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mvocab_size])\n",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(sentence, MAX_LENGTH, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 디코더의 예측 시작\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(MAX_LENGTH):\n\u001b[0;32m---> 13\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# 현재 시점의 예측 단어를 받아온다.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m predictions[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:, :]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ko_grammer_checker/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ko_grammer_checker/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7163\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7164\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"embedding_16\" (type Embedding).\n\nindices[0,0] = 8257 is not in [0, 8224) [Op:ResourceGather]\n\nCall arguments received by layer \"embedding_16\" (type Embedding):\n  • inputs=tf.Tensor(shape=(1, 15), dtype=float32)"
     ]
    }
   ],
   "source": [
    "predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9972260e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ko_grammer_checker] *",
   "language": "python",
   "name": "conda-env-ko_grammer_checker-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
