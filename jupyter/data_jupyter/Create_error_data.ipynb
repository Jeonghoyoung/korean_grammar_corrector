{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39fb81de",
   "metadata": {},
   "source": [
    "### 오류 데이터 생성.\n",
    "\t- G2P(Grapheme to Phoneme)를 이용한 오류 데이터 생성. (g2pk 모듈 사용)\n",
    "\t- 자모 단위 철자 오류 데이터 생성.\n",
    "\t- 통번역 데이터 기반 오류 데이터 생성. -> 오탈자 리스트 구축이 필요함.\n",
    "    \n",
    "    - Transformer VS Language model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cd1287",
   "metadata": {},
   "source": [
    "#### Data set\n",
    "\n",
    "- 전체 데이터\n",
    "    1. G2P data : 50%\n",
    "    2. 자모 단위 철자 오류 데이터 : 50%\n",
    "    \n",
    "    -- ** 통번역 데이터 기반 오류 데이터의 경우 리스트 구축에 시간소모가 클 것으로 예상되어 우선 제외함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04bce620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from g2pk import G2p\n",
    "from levenshtein_finder import LevenshteinFinder , CharacterTokenizer , Normalizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8121322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'갑써치'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2p = G2p()\n",
    "g2p('값어치')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c491c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data'\n",
    "enko = pd.read_csv('../data/aihub_food_enko.csv')\n",
    "zhko = pd.read_csv('../data/aihub_food_zhko.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec217acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([enko[['tgt']], zhko[['tgt']]], axis=0)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "ko = df['tgt'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2d927861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 tgt\n",
      "0  이 문제에 대한 새로운 접근법은 나이신과 같은 항균제를 식품 가공 표면에 흡착시키는...\n",
      "1        격막 형성의 실패는 아마도 세포가 격막 합성을 시작하지 못하기 때문일 것이다.\n",
      "2  지난 세기 말에 베네수엘라의 로드니우스 프롤릭서스와 브라질의 또 다른 중요한 샤가스...\n",
      "3   모기 풀 스크리닝은 바이러스 활동에 대한 가장 시기적절한 지표를 제공할 가능성이 있다.\n",
      "4               사립학교 아이들은 공립학교 아이들보다 아스파탐을 덜 섭취했습니다.\n",
      "733822\n"
     ]
    }
   ],
   "source": [
    "r_list = []\n",
    "for i in range(len(df)):\n",
    "    if len(re.findall('[^ㄱ-힣|\\.|\\s]', df['tgt'][i])) == 0:\n",
    "        r_list.append(i)\n",
    "only_ko = df.loc[r_list]\n",
    "only_ko.reset_index(inplace=True, drop=True)\n",
    "print(only_ko.head())\n",
    "print(len(only_ko))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4df570f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(825)\n",
    "np.random.seed(826)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fe3b6ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                            | 0/50000 [74:35:43<?, ?it/s]\n",
      "  0%|                                                                                                                            | 0/50000 [74:35:16<?, ?it/s]\n",
      "  0%|                                                                                                                            | 0/50000 [74:35:08<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# 말뭉치 단어 토크나이징(split) \n",
    "corpus = [sent.strip().split(\" \") for sent in only_ko['tgt'].tolist()]\n",
    "\n",
    "# 2차원 리스트(문장이 단어로 분리된)를 1차원으로 통합(단어 단위)\n",
    "corpus = list(itertools.chain(*corpus))\n",
    "\n",
    "# 중복된 단어 제거\n",
    "corpus = list(set(corpus))\n",
    " \n",
    "# 자소 단위로 쪼개서 편집거리를 구하는 알고리즘.\n",
    "normalizer = Normalizers.create_normalizer(unicodedata=True)\n",
    "tokenizer = CharacterTokenizer(normalizer=normalizer)\n",
    "finder = LevenshteinFinder(tokenizer=tokenizer)\n",
    "finder.indexing(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "53c71928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'idx': 160396, 'data': '매해', 'distance': 1},\n",
       " {'idx': 322918, 'data': '무해', 'distance': 1}]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 편집거리 테스트\n",
    "finder.search('뭐해')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdb6c75",
   "metadata": {},
   "source": [
    "### 노이즈 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1a438c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko = only_ko['tgt'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d60f4c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_idx = random.sample(range(len(ko)), 100000)\n",
    "error_idx = random.sample(t_idx, len(t_idx)//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "45c1e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = only_ko.loc[t_idx]\n",
    "# df_t.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a586b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp = df_t[['tgt']].loc[error_idx]\n",
    "edit_dist = df_t[['tgt']].drop(error_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a5a020f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp.reset_index(inplace=True, drop=True)\n",
    "edit_dist.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d9e05190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "733822\n",
      "50000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(only_ko))\n",
    "print(len(gtp))\n",
    "print(len(edit_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "87c5639d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'증류수로 희석한 탈지유와 수프는 생산자 지침에 표시된 농도의 절반으로 증류수로 만들었다.'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtp['tgt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "53760252",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [25:12<00:00, 33.06it/s]\n"
     ]
    }
   ],
   "source": [
    "g2p_data = [g2p(gtp['tgt'][k]) for k in tqdm(range(len(gtp)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "89188e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "증뉴수로 히서칸 탈지유와 수프는 생산자 지치메 표시된 농도의 절바느로 증뉴수로 만드럳따.\n",
      "증류수로 희석한 탈지유와 수프는 생산자 지침에 표시된 농도의 절반으로 증류수로 만들었다.\n"
     ]
    }
   ],
   "source": [
    "print(g2p_data[0])\n",
    "print(gtp['tgt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9d6a9e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_begin = 44032\n",
    "kor_end = 55203\n",
    "\n",
    "chosung_base = 588\n",
    "jungsung_base = 28\n",
    "\n",
    "jaum_begin = 12593\n",
    "jaum_end = 12622\n",
    "\n",
    "moum_begin = 12623\n",
    "moum_end = 12643\n",
    "\n",
    "chosung_list = [ 'ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', \n",
    "        'ㅅ', 'ㅆ', 'ㅇ' , 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "jungsung_list = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', \n",
    "        'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', \n",
    "        'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', \n",
    "        'ㅡ', 'ㅢ', 'ㅣ', ' ']\n",
    "\n",
    "jongsung_list = [\n",
    "    ' ', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ',\n",
    "        'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', \n",
    "        'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', \n",
    "        'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "jaum_list = ['ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄸ', 'ㄹ', \n",
    "              'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', \n",
    "              'ㅃ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "moum_list = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', \n",
    "              'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "\n",
    "def compose(chosung, jungsung, jongsung):\n",
    "    # 자음 모음 결합\n",
    "    char = chr(\n",
    "        kor_begin +\n",
    "        chosung_base * chosung_list.index(chosung) +\n",
    "        jungsung_base * jungsung_list.index(jungsung) +\n",
    "        jongsung_list.index(jongsung)\n",
    "    )\n",
    "    return char\n",
    "\n",
    "def decompose(c):\n",
    "    # 자음 모음 분해\n",
    "    if not character_is_korean(c):\n",
    "        return None\n",
    "    i = ord(c)\n",
    "    if (jaum_begin <= i <= jaum_end):\n",
    "        return (c, ' ', ' ')\n",
    "    if (moum_begin <= i <= moum_end):\n",
    "        return (' ', c, ' ')\n",
    "\n",
    "    # decomposition rule\n",
    "    i -= kor_begin\n",
    "    cho  = i // chosung_base\n",
    "    jung = ( i - cho * chosung_base ) // jungsung_base \n",
    "    jong = ( i - cho * chosung_base - jung * jungsung_base )    \n",
    "    return (chosung_list[cho], jungsung_list[jung], jongsung_list[jong])\n",
    "\n",
    "def character_is_korean(c):\n",
    "    i = ord(c)\n",
    "    return ((kor_begin <= i <= kor_end) or\n",
    "            (jaum_begin <= i <= jaum_end) or\n",
    "            (moum_begin <= i <= moum_end))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "87aea912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a545f058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.51 s, sys: 6.76 ms, total: 1.51 s\n",
      "Wall time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dist_list = []\n",
    "for i in range(len(edit_dist)):\n",
    "    # 띄어쓰기를 기준으로 split\n",
    "    split_t = edit_dist['tgt'][i].split()\n",
    "    \n",
    "    # sample number\n",
    "    sample_num = random.randrange(1,4)\n",
    "    \n",
    "    # 샘플 갯수에 맞게 choose\n",
    "    if len(split_t) <= sample_num:\n",
    "        sample_num = sample_num - 1\n",
    "        rand_t = random.sample(range(len(split_t)), sample_num)\n",
    "    else:\n",
    "        rand_t = random.sample(range(len(split_t)), sample_num)\n",
    "    \n",
    "    for n in rand_t:\n",
    "        # 한글 제외 모두 제거.\n",
    "        repl_text = re.sub('[^ㄱ-힣]', '', split_t[n])\n",
    "        repl_text = repl_text.strip()\n",
    "        repl_text = repl_text.replace(' ', '')\n",
    "        \n",
    "        t = random.choice(range(len(repl_text)))\n",
    "        \n",
    "        # 자모 분리\n",
    "        decomp_text = decompose(repl_text[t])\n",
    "        decomp_text = list(decomp_text)\n",
    "        c = random.choice(range(len(decomp_text)))\n",
    "        \n",
    "        if decomp_text[c] in jongsung_list:\n",
    "            if c == 0:\n",
    "                decomp_text[c] = random.choice(chosung_list)\n",
    "                comp = compose(decomp_text[c], decomp_text[1], decomp_text[-1])\n",
    "            elif c == 2:\n",
    "                decomp_text[c] = random.choice(jongsung_list)\n",
    "                comp = compose(decomp_text[0], decomp_text[1], decomp_text[c])\n",
    "                \n",
    "        elif decomp_text[c] in jungsung_list:\n",
    "            if len(decomp_text) == 2:\n",
    "                decomp_text[c] = random.choice(jungsung_list)\n",
    "                comp = compose(decomp_text[0], decomp_text[c])\n",
    "            elif len(decomp_text) > 2:\n",
    "                decomp_text[c] = random.choice(jungsung_list)\n",
    "                comp = compose(decomp_text[0], decomp_text[c], decomp_text[-1])\n",
    "        \n",
    "        # 변환을 위한 문자열 -> list\n",
    "        text_l = list(repl_text)\n",
    "        text_l[t] = comp\n",
    "        repl_text = ''.join(text_l)\n",
    "        split_t[n] = repl_text\n",
    "    dist = ' '.join(split_t)\n",
    "    \n",
    "    dist_list.append(dist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c6b64c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e6c2b45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'중국엂로 조리는 먹을 새 있는 것을 특정한 방식으로 익힌다는 것을 의미함뜰 알 수 있습니다.'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7d388735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'중국어로 조리는 먹을 수 있는 것을 특정한 방식으로 익힌다는 것을 의미함을 알 수 있습니다.'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_dist['tgt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8b0ffbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g2p를 사용한 오타데이터 : g2p_data\n",
    "# 자모 분리후 오타 데이터 생성 : dist_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "17d5ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_gtp = gtp['tgt'].tolist()\n",
    "raw_dist = edit_dist['tgt'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5570ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = g2p_data + dist_list\n",
    "tgt = raw_gtp + raw_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "9254d6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "농촌단체급씨긔 식푸만전괄리는 지방정부의 성과평가내용과 중요지표에 포함되어야 하며 농촌단체급씨긔 식푸만전괄리영냥은 지속쩌그로 강화해야 함니다.\n",
      "농촌단체급식의 식품안전관리는 지방정부의 성과평가내용과 중요지표에 포함되어야 하며 농촌단체급식의 식품안전관리역량은 지속적으로 강화해야 합니다.\n",
      "아유 시장 옹호자들과 자유지상주의자들은 옥수수 보조금이 만들어내는 시장 왜곡괃 비효율성을 오랫동안 비난해 왔다.\n",
      "자유 시장 옹호자들과 자유지상주의자들은 옥수수 보조금이 만들어내는 시장 왜곡과 비효율성을 오랫동안 비난해 왔다.\n"
     ]
    }
   ],
   "source": [
    "print(src[200])\n",
    "print(tgt[200])\n",
    "\n",
    "print(src[50001])\n",
    "print(tgt[50001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c6f4df89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>증뉴수로 히서칸 탈지유와 수프는 생산자 지치메 표시된 농도의 절바느로 증뉴수로 만드럳따.</td>\n",
       "      <td>증류수로 희석한 탈지유와 수프는 생산자 지침에 표시된 농도의 절반으로 증류수로 만들었다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>다른 한펴느로는 파괴려게 대한 함니저기 뉴연성과 빌딩 블록꽈 신호 분자가 사라인는 ...</td>\n",
       "      <td>다른 한편으로는 파괴력에 대한 합리적인 유연성과 빌딩 블록과 신호 분자가 살아있는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>식푸뮈생감도근 기술과제임과 동시에 버베 따른 행정저 검무로서 감독짜는 견실하고 유연...</td>\n",
       "      <td>식품위생감독은 기술과제임과 동시에 법에 따른 행정적 업무로서 감독자는 견실하고 유연...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>예시메 합껴칸 자는 시 품질감독뿌서가 성급 품질감독뿌서와 품질감독껌사거멱총구게 보고...</td>\n",
       "      <td>예심에 합격한 자는 시 품질감독부서가 성급 품질감독부서와 품질감독검사검역총국에 보고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>케이크 가루는 기포 분포가 매우 규닐하며 베이킹 후에도 월래 구조가 여전히 유지되고...</td>\n",
       "      <td>케이크 가루는 기포 분포가 매우 균일하며 베이킹 후에도 원래 구조가 여전히 유지되고...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 src  \\\n",
       "0  증뉴수로 히서칸 탈지유와 수프는 생산자 지치메 표시된 농도의 절바느로 증뉴수로 만드럳따.   \n",
       "1  다른 한펴느로는 파괴려게 대한 함니저기 뉴연성과 빌딩 블록꽈 신호 분자가 사라인는 ...   \n",
       "2  식푸뮈생감도근 기술과제임과 동시에 버베 따른 행정저 검무로서 감독짜는 견실하고 유연...   \n",
       "3  예시메 합껴칸 자는 시 품질감독뿌서가 성급 품질감독뿌서와 품질감독껌사거멱총구게 보고...   \n",
       "4  케이크 가루는 기포 분포가 매우 규닐하며 베이킹 후에도 월래 구조가 여전히 유지되고...   \n",
       "\n",
       "                                                 tgt  \n",
       "0  증류수로 희석한 탈지유와 수프는 생산자 지침에 표시된 농도의 절반으로 증류수로 만들었다.  \n",
       "1  다른 한편으로는 파괴력에 대한 합리적인 유연성과 빌딩 블록과 신호 분자가 살아있는 ...  \n",
       "2  식품위생감독은 기술과제임과 동시에 법에 따른 행정적 업무로서 감독자는 견실하고 유연...  \n",
       "3  예심에 합격한 자는 시 품질감독부서가 성급 품질감독부서와 품질감독검사검역총국에 보고...  \n",
       "4  케이크 가루는 기포 분포가 매우 균일하며 베이킹 후에도 원래 구조가 여전히 유지되고...  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df = pd.DataFrame({'src':src, 'tgt':tgt})\n",
    "\n",
    "t_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "88d70263",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df.to_csv('../data/korean_correct_train_data_100000.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cfb079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc4cc26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b954557e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e72119c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff5f1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec98d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grammar-Correcter",
   "language": "python",
   "name": "kogrammer_checker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
