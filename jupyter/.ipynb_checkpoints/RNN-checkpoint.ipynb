{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b2a8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-26 17:37:27.836771: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, GRU,Dense, SimpleRNN, TimeDistributed, Activation, RepeatVector,Bidirectional, Embedding\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb692d31",
   "metadata": {},
   "source": [
    "## RNN\n",
    "***\n",
    "- 입력과 출력을 시퀀스 단위로 처리하는 시퀀스 모델.\n",
    "- 은닉층의 노드에서 활성화 함수를 통해 나온 결과값을 출력층 방향으로 보내면서, 다시 은닉층 노드의 다음 계산의 입력으로 보내는 특징을 갖고 있다.\n",
    "- RNN에서 은닉층에서 활성화 함수를 통해 결과를 내보내는 역할을 하는 노드를 셀이라고 하며, 이 셀은 이전의 값을 기억하려고 하는 일종의 메모리 역할을 수행한다.\n",
    "\n",
    "\n",
    "현재 시점 t에서의 은닉 상태값을 $ h_t $ 라 하였을때, 은닉측의 메모리 셀은 $ h_t $ 를 계산하기 위해서 총 두개의 가중치를 가진다.\n",
    "하나는 입력층을 위한 가중치 $ W_x $, 다른 하나는 이전 시점 $ t-1 $ 의 은닉 상태값인 $ h_{t-1} $ 을 위한 가중치 $ W_h $ 이다.\n",
    "\n",
    "\n",
    "- 은닉층 : $ h_t = tanh(W_x x_t + W_hh{t-1} + b) $\n",
    "- 출력층 : $ y_t = f(W_yh_t + b) $\n",
    "- 단 , $f$는 비선형 활성화 함수 중 하나\n",
    "\n",
    "    - $x_t$ : 단어 벡터, $d$ : 단어 벡터의 차원, $D_h$: 은닉 상태의 크기\n",
    "    - $x_t = (d * 1)$\n",
    "    - $W_x = (D_h * d)$\n",
    "    - $W_h = (D_h * D_h)$\n",
    "    - $h_{t-1} = (D_h * 1)$\n",
    "    - $b = (D_h * 1)$\n",
    "\n",
    "\n",
    "#### RNN Input\n",
    "***\n",
    "- RNN 층은 (batch_size, timesteps, input_dim) 크기의 3D 텐서를 입력 받는다. \n",
    "- batch_size = 한 번에 학습하는 데이터의 개수\n",
    "\n",
    "- hidden_units = 은닉 상태의 크기를 정의. 메모리 셀이 다음 시점의 메모리 셀과 출력층으로 보내는 값의 크기(output_dim)와도 동일. RNN의 용량(capacity)을 늘린다고 보면 되며, 중소형 모델의 경우 보통  __128, 256, 512, 1024__ 등의 값을 가진다.\n",
    "- timesteps = 입력 시퀀스의 길이(input_length)라고 표현하기도 함. 시점의 수. (__자연어 처리에서는 문장의 길이__)\n",
    "- input_dim = 입력의 크기. (__자연어 처리에서는 단어 벡터의 차원__)\n",
    "\n",
    "\n",
    "#### 은닉 상태 출력\n",
    "***\n",
    "- 메모리 셀의 최종 시점의 은닉 상태만을 리턴하고자 한다면 (batch_size, output_dim) 크기의 2D 텐서\n",
    "\n",
    "- 메모리 셀의 각 시점(time step)의 은닉 상태값들을 모아서 전체 시퀀스를 리턴하고자 한다면 (batch_size, timesteps, output_dim) 크기의 3D 텐서\n",
    "\n",
    "    - RNN 층의 return_sequences 매개 변수에 True를 설정하여 설정 가능\n",
    "    - 마지막 은닉 상태만 전달하도록 하면 다 대 일(many-to-one) 문제를 풀 수 있고, 모든 시점의 은닉 상태를 전달하도록 하면, 다음층에 RNN 은닉층이 하나 더 있는 경우이거나 다 대 다(many-to-many) 문제를 풀 수 있다.\n",
    "\n",
    "\n",
    "#### Deep RNN\n",
    "***\n",
    "- 은닉층이 1개가 아닌 2개 이상 더 쌓은 모습\n",
    "-------------\n",
    "```python\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(hidden_units, input_length=10, input_dim=5, return_sequences=True))\n",
    "model.add(SimpleRNN(hidden_units, return_sequences=True))\n",
    "\n",
    "```\n",
    "-------------\n",
    "\n",
    "#### 양방향 RNN\n",
    "***\n",
    "- 양방향 순환 신경망은 시점 t에서의 출력값을 예측할 때 이전 시점의 입력뿐만 아니라, 이후 시점의 입력 또한 예측에 기여할 수 있다.\n",
    "- 이전과 이후의 시점 모두를 고려해서 현재 시점의 예측을 더욱 정확하게 할 수 있도록 고안된 것이 양방향 RNN\n",
    "\n",
    "    - 하나의 출력값을 예측하기 위해 기본적으로 두 개의 메모리 셀을 사용.\n",
    "    - 첫번째 메모리 셀은 앞에서 배운 것처럼 앞 시점의 은닉 상태(Forward States) 를 전달받아 현재의 은닉 상태를 계산.\n",
    "    - 두번째 메모리 셀은 앞 시점의 은닉 상태가 아니라 뒤 시점의 은닉 상태(Backward States) 를 전달 받아 현재의 은닉 상태를 계산. (__입력 시퀀스를 반대 방향으로 읽는 것__)\n",
    "\n",
    "-------------\n",
    "```python\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "timesteps = 10\n",
    "input_dim = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True), input_shape=(timesteps, input_dim)))\n",
    "\n",
    "```\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a82f5c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 3)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-26 13:22:19.553861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, input_shape=(2,10)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3eadce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_1 (SimpleRNN)    (8, 3)                    42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8,2,10)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa699a06",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9834001",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd4e9469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{path}/korean_correct_train_data_100000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0979fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>증뉴수로 히서칸 탈지유와 수프는 생산자 지치메 표시된 농도의 절바느로 증뉴수로 만드럳따.</td>\n",
       "      <td>증류수로 희석한 탈지유와 수프는 생산자 지침에 표시된 농도의 절반으로 증류수로 만들었다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>다른 한펴느로는 파괴려게 대한 함니저기 뉴연성과 빌딩 블록꽈 신호 분자가 사라인는 ...</td>\n",
       "      <td>다른 한편으로는 파괴력에 대한 합리적인 유연성과 빌딩 블록과 신호 분자가 살아있는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>식푸뮈생감도근 기술과제임과 동시에 버베 따른 행정저 검무로서 감독짜는 견실하고 유연...</td>\n",
       "      <td>식품위생감독은 기술과제임과 동시에 법에 따른 행정적 업무로서 감독자는 견실하고 유연...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>예시메 합껴칸 자는 시 품질감독뿌서가 성급 품질감독뿌서와 품질감독껌사거멱총구게 보고...</td>\n",
       "      <td>예심에 합격한 자는 시 품질감독부서가 성급 품질감독부서와 품질감독검사검역총국에 보고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>케이크 가루는 기포 분포가 매우 규닐하며 베이킹 후에도 월래 구조가 여전히 유지되고...</td>\n",
       "      <td>케이크 가루는 기포 분포가 매우 균일하며 베이킹 후에도 원래 구조가 여전히 유지되고...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 src  \\\n",
       "0  증뉴수로 히서칸 탈지유와 수프는 생산자 지치메 표시된 농도의 절바느로 증뉴수로 만드럳따.   \n",
       "1  다른 한펴느로는 파괴려게 대한 함니저기 뉴연성과 빌딩 블록꽈 신호 분자가 사라인는 ...   \n",
       "2  식푸뮈생감도근 기술과제임과 동시에 버베 따른 행정저 검무로서 감독짜는 견실하고 유연...   \n",
       "3  예시메 합껴칸 자는 시 품질감독뿌서가 성급 품질감독뿌서와 품질감독껌사거멱총구게 보고...   \n",
       "4  케이크 가루는 기포 분포가 매우 규닐하며 베이킹 후에도 월래 구조가 여전히 유지되고...   \n",
       "\n",
       "                                                 tgt  \n",
       "0  증류수로 희석한 탈지유와 수프는 생산자 지침에 표시된 농도의 절반으로 증류수로 만들었다.  \n",
       "1  다른 한편으로는 파괴력에 대한 합리적인 유연성과 빌딩 블록과 신호 분자가 살아있는 ...  \n",
       "2  식품위생감독은 기술과제임과 동시에 법에 따른 행정적 업무로서 감독자는 견실하고 유연...  \n",
       "3  예심에 합격한 자는 시 품질감독부서가 성급 품질감독부서와 품질감독검사검역총국에 보고...  \n",
       "4  케이크 가루는 기포 분포가 매우 균일하며 베이킹 후에도 원래 구조가 여전히 유지되고...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c868f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['src'], df['tgt'], test_size=0.2, shuffle=True, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9733c5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48472    산양 거래시장과 농업정보시스템 건설을 강화하고 교통반경에 따라 점을 합리적으로 배치...\n",
       "5937                   향후 연구에서는 멜라토닌과 같은 다른 약물도 테스트할 수 있다.\n",
       "7467                    그러나 이 지역은 슈도모나스 종을 만족스럽게 구별하지 못한다.\n",
       "2395     카파 경쇄의 체세포 돌연변이는 모체 항지랄레논 항체의 생체 내 친화성 성숙 동안 발...\n",
       "68514           가공 과정과 생산 가공 과정이 공정 설계 요구사항을 충족하는지 여부가 있다.\n",
       "                               ...                        \n",
       "68693            일부 새로운 결과는 생물막 연구에 열량측정법을 적용할 수 있음을 보여준다.\n",
       "93942    물품을 추적하기 위해 모든 포장 상자에는 과수원 등록 번호와 포장 공장 등록 번호를...\n",
       "22377    사료 원료의 선택은 고품질 및 용이한 소화성을 원칙으로 하고 미코톡신이 함유된 사료...\n",
       "43498                    방목지를 초원으로 되돌리는 프로젝트의 실행 속도를 높입니다.\n",
       "77217    식초 양조 과정에는 많은 미생물이 관여하고 그에 따라 많은 대사 산물이 생성되지만 ...\n",
       "Name: tgt, Length: 80000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c172b554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48472    사냥 거래시장과 농업쩡보시스템 건서를 강화하고 교통반경에 따라 저믈 함니저그로 배치...\n",
       "5937                   향후 연구에서는 멜라토닌과 가튼 다르 냥물도 테스트할 쑤 읻따.\n",
       "7467                    그러나 이 지여근 슈도모나스 종을 만족쓰럽께 구별하지 모탄다.\n",
       "2395     카파 경쇄의 체세포 도련벼니는 모체 항지랄레논 항체의 생체 내 친화성 성숙 똥안 발...\n",
       "68514           가공 괓정과 생산 가공 과정이 공정 설계 요구사항을 충족하는지 여부가 있다.\n",
       "                               ...                        \n",
       "68693            일부 새로운 결과는 생물막 연구에 열량측정법을 적용핣 수 있음을 보여준다.\n",
       "93942    물품을 추적하기 위해 모든 포장 짱자에는 과수원 등록 번호와 포장 공장 등록 번호를...\n",
       "22377    사료 월료의 선태근 고품질 미 둉이한 소화성으 뤈치그로 하고 미코톡씨니 하뮤된 사료...\n",
       "43498                    방목찌를 초워느로 되돌리는 프로젝트의 실행 속또를 로핌니다.\n",
       "77217    식초 양조 과정에는 많은 미생물이 관여하고 그에 따라 많은 대사 산뭌이 생성되지만 ...\n",
       "Name: src, Length: 80000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d31ceccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary\n",
    "\n",
    "src_words_counter = Counter([word for s in df['src'].tolist() for word in s.split()])\n",
    "tgt_words_counter = Counter([word for s in df['tgt'].tolist() for word in s.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7975c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    \"\"\"\n",
    "    Tokenize x\n",
    "    :param x: List of sentences/strings to be tokenized\n",
    "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    x_tk = Tokenizer()\n",
    "    x_tk.fit_on_texts(x)\n",
    " \n",
    "    return x_tk.texts_to_sequences(x), x_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d34929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x, length=None):\n",
    "    \"\"\"\n",
    "    Pad x\n",
    "    :param x: List of sequences.\n",
    "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
    "    :return: Padded numpy array of sequences\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    if length is None:\n",
    "        length = max([len(sentence) for sentence in x])\n",
    "    return pad_sequences(x, maxlen=length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d6a63e",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bec892f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x,y):\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    " \n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "    \n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    " \n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "666c63ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_x, prep_y, x_tok, y_tok = preprocess(df['src'], df['tgt'])\n",
    "\n",
    "max_src_sequence_length = prep_x.shape[1]\n",
    "max_tgt_sequence_length = prep_y.shape[1]\n",
    "src_vocab_size = len(x_tok.word_index)\n",
    "tgt_vocab_size = len(y_tok.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abf95494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = {idx: word for word, idx in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    " \n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8d48a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "def simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a basic RNN on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Build the layers\n",
    "    learning_rate = 1e-3\n",
    "    model = Sequential()\n",
    "    model.add(GRU(128, input_shape=input_shape[1:], return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(GRU(128, return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \n",
    "     \n",
    "     \n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "343c0edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpx = pad(prep_x, max_tgt_sequence_length)\n",
    "tmpx = tmpx.reshape((-1,prep_y.shape[-2], 1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ff3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_model = simple_model(\n",
    "    tmpx.shape,\n",
    "    max_tgt_sequence_length,\n",
    "    src_vocab_size,\n",
    "    tgt_vocab_size)\n",
    "\n",
    "simple_rnn_model.fit(tmpx, prep_y, batch_size=300, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08533144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grammar-Correcter",
   "language": "python",
   "name": "kogrammer_checker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
